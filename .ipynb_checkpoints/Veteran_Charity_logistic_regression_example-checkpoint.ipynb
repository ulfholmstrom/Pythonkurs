{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "__The veteran dataset contains 44 variables that describes the features for givers and non-givers for a charity campaign. The label that defines a donation is Target_B.__ \n",
    "\n",
    "\n",
    "- Target_B = 1: donation\n",
    "- Target_B = 0: No donation \n",
    "\n",
    "__Below is an example how to apply a logistic regression model on the data in order to predict the likelihood for donation. The model is evaulated with a so called ROC curve__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pylab as plt \n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import data into a dataframe. Look at the 10 first observations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"veteran_brutto.csv\" )\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Deskriptiv statistik__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cts = (df['URBANICITY'].value_counts())\n",
    "\n",
    "# Definierar hela arean\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "# Skapar grafobjekt som ska läggas in i arean ovan\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.set_title('URBANICITY')\n",
    "\n",
    "\n",
    "m_cts.plot(kind='bar', rot = 0, grid = False, alpha = 0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cts = (df['SES'].value_counts())\n",
    "\n",
    "# Definierar hela arean\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "# Skapar grafobjekt som ska läggas in i arean ovan\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.set_title('SES')\n",
    "\n",
    "\n",
    "m_cts.plot(kind='bar', rot = 0, grid = False, alpha = 0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cts = (df['DONOR_GENDER'].value_counts())\n",
    "\n",
    "# Definierar hela arean\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "# Skapar grafobjekt som ska läggas in i arean ovan\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.set_title('GENDER')\n",
    "\n",
    "\n",
    "m_cts.plot(kind='bar', rot = 0, grid = False, alpha = 0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Väljer enbart observationer om man är man eller kvinna\n",
    "\n",
    "df_subset = df[(df['DONOR_GENDER'] == 'F') | (df['DONOR_GENDER'] == 'M')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definierar hela arean\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "# Skapar grafobjekt som ska läggas in i arean ovan\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.set_title('Age')\n",
    "\n",
    "\n",
    "plt.hist(df_subset['DONOR_AGE'], bins = 20, alpha = 0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nu vill vi göra en klassificeringsmodell för att prediktera sannolikhet för donation. Vill skapa ett dynamiskt flöde för att hantera alla olika datatyper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Först måste vi separera kategori variabler från numeriska - dessa ska hanteras på olika sätt\n",
    "* Kategorivariabler - skapa dummy variabler\n",
    "* Numeriska variabler - imputera missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = []\n",
    "cat_attribs = []\n",
    "for var, typ in zip(df.columns[1:], df.dtypes[1:]):\n",
    "    if typ == 'object':\n",
    "        cat_attribs.append(var)\n",
    "    else:\n",
    "        num_attribs.append(var)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = num_attribs + cat_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nu vill vi bygga en pipeline som hanterar kategorivariabler, missing values samt utför en logistisk regrssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to avoid overfitting data is split into training data and validation data. 75% träningsdata och 25% valideringsdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['is_train']=np.random.uniform(0,1,len(df_subset))<=0.75\n",
    "\n",
    "train, validate = df_subset[df_subset['is_train']==True], df_subset[df_subset['is_train']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[cols].copy()\n",
    "X_validate = validate[cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['TARGET_B']\n",
    "y_validate = validate['TARGET_B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sätter upp en pipeline som gör det möjligt att hantera flödet dynamiskt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regrssion object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding object\n",
    "\n",
    "- This is the same as \"dummy encoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute object for missing values\n",
    "\n",
    "Missing values:\n",
    "\n",
    "- Imputation means that you are filling in missing values based on what you know from the non-missing data\n",
    "- Carefully consider the costs and benefits of imputation before proceeding, because you are making up data\n",
    "\n",
    "Use SimpleImputer to perform the imputation:\n",
    "\n",
    "- It requires 2-dimensional input (just like OneHotEncoder)\n",
    "- By default, it fills missing values with the mean of the non-missing values\n",
    "- It also supports other imputation strategies: median value, most frequent value, or a user-defined value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu skapar vi ett column transformer objekt som utför one hot encoding på kategorivariabler och imouterar missing värden__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, cat_attribs),\n",
    "    (imp, num_attribs)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definerar vår pipeline - Denna pipeline utför one-hot encoding samt imoputerar medelvärde för missing numeriska variabler. Dessutom så utför den en logistisk regression som ett sista steg__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(ct,logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu kör vi vår pipeline. Fit metoden tar fram parametrarna för datat som kommer ut från vår pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on the training data and then evaluate on the validation data\n",
    "\n",
    "- predicts: A twodimensional array that contains posterrior probabbility for a donation behaviour, one for non-donation and one for donation\n",
    "- fpr : False positive rate, number of false positive for a specific threshold value\n",
    "- tpr : True positive rate, number of true positive for a specific threshold value\n",
    "- threshold: Sorted threshold (descending) values for the likelihod to donate\n",
    "- roc_auc: Receiver operating characteristics. A value close to 1 indicates a strong model. A value close to 0.5 means that the model is rather poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predikterar med modellen med valideringsdata\n",
    "\n",
    "predict = pipeline.predict_proba(X_validate)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_validate,predict[:,1])\n",
    "\n",
    "roc_auc = auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A ROC curve for the charity classifier on the charity data\n",
    "\n",
    "__It traces out two types of error as we vary the threshold value for the posterior probability of charity. The actual thresholds are not shown. The true positive rate is the sensitivity: the fraction of givers that are correctly identified, using a given threshold value. The false positive rate is 1-specificity: the fraction of non-givers that we classify incorrectly as givers, using that same threshold value. The ideal ROC curve hugs the top left corner, indicating a high true positive rate and a low false positive rate. The dotted line represents the “no information” classifier.__ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graf AUC\n",
    "\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "\n",
    "plt.title('Receiver Operating Characteristic') \n",
    "plt.plot( fpr, tpr, 'b', label =' AUC = %0.3f' % roc_auc) \n",
    "plt.legend( loc ='lower right') \n",
    "plt.plot([ 0, 1], [0, 1], 'r--') \n",
    "plt.xlim([ 0.0, 1.0]) \n",
    "plt.ylim([ 0.0, 1.0]) \n",
    "plt.ylabel('True positive rate') \n",
    "plt.xlabel('False positive rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
