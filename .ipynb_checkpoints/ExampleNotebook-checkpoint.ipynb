{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example notebook - example of pattern used: mix of Hive sql, pandas and pySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__First we need to open our spark session__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./utils_newcluster.py\n",
    "spark = connect_to_datalake(\"exampleNotebook\")\n",
    "from pyspark_llap import HiveWarehouseSession\n",
    "hive = HiveWarehouseSession.session(spark).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions and datatypes\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__First an example of using Hive and create a pandas dataframe. Pattern: Do the heavy data transfomration in Hive SQL and then download to pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set database\n",
    "\n",
    "hive.setDatabase('''appl_transport_index''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Execute Hive query and apply toPnadas method to create pandas dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week =  hive.executeQuery('''\n",
    "                                select \n",
    "                                max(c.enddate) as start_date\n",
    "                                ,c.weeknumber as week_number\n",
    "                                ,b.countryname as country_name\n",
    "                                ,b.segment as segment\n",
    "                                ,count(a.chassisnumber) as number_of_vehicles\n",
    "                                ,c.yearnumber  as year_number\n",
    "                                ,avg(totalruntime)/numberofdays    as mean_runtime_per_day\n",
    "                                ,avg(odometer)/numberofdays as mean_driven_distance_per_day                             \n",
    "                                from vehicle_time_series_weekly_fact a inner join vehicle_dimension b\n",
    "                                on a.chassisnumber = b.chassisnumber\n",
    "                                inner join week_dim c\n",
    "                                 on a.startdate = c.startdate\n",
    "                                 where (\n",
    "                                   (a.startdate between (\"2020-01-05\") and (\"2021-01-05\"))  \n",
    "                                    or (a.startdate between (\"2019-01-05\") and (\"2019-10-07\"))\n",
    "                                    )   \n",
    "                                and a.age_category IN(\"age_0_3\", \"age_3_6\", \"age_6_9\", \"age_9__\")\n",
    "                                 group by c.yearnumber, c.weeknumber, b.countryname, b.segment, c.numberofdays\n",
    "                                 ''').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__df_week is now a pandas object and now we can continue with the pandas API to do more sofisticated stuff__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>week_number</th>\n",
       "      <th>country_name</th>\n",
       "      <th>segment</th>\n",
       "      <th>number_of_vehicles</th>\n",
       "      <th>year_number</th>\n",
       "      <th>mean_runtime_per_day</th>\n",
       "      <th>mean_driven_distance_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-16</td>\n",
       "      <td>24</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Haulage</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.397917</td>\n",
       "      <td>270.131429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>29</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Buses other</td>\n",
       "      <td>1581</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.030818</td>\n",
       "      <td>149.595017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>9</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Distribution</td>\n",
       "      <td>156</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.765770</td>\n",
       "      <td>168.166813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Distribution</td>\n",
       "      <td>193</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.668880</td>\n",
       "      <td>171.606669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>49</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Distribution</td>\n",
       "      <td>210</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.980106</td>\n",
       "      <td>183.790476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date  week_number country_name       segment  number_of_vehicles  \\\n",
       "0  2019-06-16           24  Afghanistan       Haulage                   4   \n",
       "1  2020-07-19           29    Australia   Buses other                1581   \n",
       "2  2019-03-03            9    Australia  Distribution                 156   \n",
       "3  2020-06-21           25    Australia  Distribution                 193   \n",
       "4  2020-12-06           49    Australia  Distribution                 210   \n",
       "\n",
       "   year_number mean_runtime_per_day mean_driven_distance_per_day  \n",
       "0         2019             4.397917                   270.131429  \n",
       "1         2020             6.030818                   149.595017  \n",
       "2         2019             3.765770                   168.166813  \n",
       "3         2020             3.668880                   171.606669  \n",
       "4         2020             3.980106                   183.790476  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_week.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__You can also utilize pySpark API. Then yoy create a spark object from the initial query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_dim1 = spark.sql(''' select *\n",
    "                    ,case\n",
    "                        when segment_pgr = 'L'             then 'Long Haulage'\n",
    "                        when segment_pgr = 'C'             then 'Construction'\n",
    "                        when segment_pgr = 'D'             then 'Distribution'\n",
    "                        when segment_ntg = 'Long distance' then 'Long Haulage'\n",
    "                        else segment_ntg\n",
    "                     end as segment                    \n",
    "                from stage_dim1\n",
    "                ''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__stage_dim1 is a spark object that you can apply pySpark API on__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern matching to derive two new variables from the column engineinfo\n",
    "stage_dim2 = stage_dim1.withColumn(\"enginetype\", F.regexp_extract(stage_dim1.engineinfo, r\"(\\w+\\d+\\s+\\d+)\", 0)). \\\n",
    "     withColumn(\"horsepower\", F.regexp_extract(stage_dim1.engineinfo, r\"(\\d+ hp)\", 0)).drop('engineinfo')\n",
    "stage_dim2.createOrReplaceTempView('stage_dim2')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Finally you can store spark tables physically as a Hive table. In the example below we store the spark table df_bus_segment as a physicall Hive table as ca_bus_segment in the hive database project_transport_index__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hive.setDatabase('''project_transport_index''')\n",
    "\n",
    "df_bus_segment.write.mode('overwrite').format(HiveWarehouseSession().HIVE_WAREHOUSE_CONNECTOR).option(\"table\", 'project_transport_index.ca_bus_segment').save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
